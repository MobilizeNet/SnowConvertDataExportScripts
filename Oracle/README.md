# Oracle Export Tool

The Oracle Export Tool consists of two parts: a query generator and a data extractor. In the following sections, you can find a brief description of these two parts, as well as, information on the building and the execution processes. 

## Query Generation

This part of the tool is in charge of the generation of simple queries over one table that will be used to extract data from the Oracle database. For the query generation we use the specs defined in a YAML file. In that configuration file there is a mandatory section in which we define a list of schemas and for each of them we can define schema and query filters. Next, you can find an example of that section in the YAML file. Also, we will explain the use of it.

```yaml
...
schemas:
    schema1:
        - schemaFilter: "TABLE_NAME = 'ORDERS'"
          queryFilter: "ORDERS.ORDER_DATE > TO_DATE('2017-10-15', 'YYYY-MM-DD')"
        - schemaFilter: "COLUMN_NAME LIKE 'ORDER_%'"
          queryFilter: ""
    schema2:
        - schemaFilter: "TABLE_NAME = 'COUNTRIES'"
          queryFilter: "COUNTRIES.CODE IN ('US', 'ES', 'DE')"
    ...
...
```

From the previous schemas definition the Query Generation integrated tool will produce at least 3 query files (depending on the schema filter we can have multiple tables involved) as follows in the corresponding directory. Each file name will have a pattern structure like *{schema}.{table_name}.{unique identifier}.sql*:

* File 1: *schema1.orders.abc123.sql*
```sql
SELECT column1, column2 FROM ORDERS WHERE ORDERS.ORDER_DATE > TO_DATE('2021-01-01', 'YYYY-MM-DD')
```

* File 2: *schema1.orders.def456.sql*
```sql
SELECT ORDER_ID FROM ORDERS;
```

* File 3: *schema1.order_items.xyz000.sql*
```sql
SELECT ORDER_CODE FROM ORDER_ITEMS;
```

* File 4: *schema2.countries.xyz789.sql*
```sql
SELECT column1, column2, column3 FROM COUNTRIES WHERE COUNTRIES.CODE IN ('US', 'ES', 'DE')
```

From the YAML definition, we will assume that file 1 was generated from the schema 1 and applying the first schema and query filter. Files 2 and 3 were generated from the schema 1 and applying the second schema and query filter. Finally, file 4 was generated from the schema 2 and applying the only schema and query filter defined for that schema.

## Data Extraction

This part of the tool is in charge of the connection to the database for the extraction of the actual data using the query script files generated by the Query Generator. For the Data Extraction we are using a tool that needs to be defined in the YAML file. We will run that tool with the parameters defined and the actual data dumps will be saved in the corresponding directory. The *extractor* parameter in the YAML file should be something like this:

`<extraction tool name> $host $port $sid $user $password $queryScriptFile $dataDumpFile`

The following are some examples of how to define the *extractor* parameter in the YAML file. 

* Powershell script
`.\extract.ps1 $host $port $sid $user $password $queryScriptFile $dataDumpFile`

* Batch file
`extract.bat $host $port $sid $user $password $queryScriptFile $dataDumpFile`

* Shell script
`.\extract.sh $host $port $sid $user $password $queryScriptFile $dataDumpFile`

## Tool Building Process

This tool has been written in Java and for building process Maven is being used. You can use any of the following commands, as a reference, to build the tool.

* `mvn clean package spring-boot:repackage`
This will produce two jar files, but the one that should be used is the one with a name similar to this: *oracle_export-1.0-SNAPSHOT.jar*

* `mvn clean package assembly:single`
This will produce two jar files, but the one that should be used is the one with a name similar to this: *oracle_export-1.0-SNAPSHOT-jar-with-dependencies.jar*

## Tool Execution Process

As mentioned before, the tool was written in Java. Hence, in order to run the tool we will need Java to be installed in our machine. Also, a YAML file needs to be created to run the Oracle Export tool. Next, you can find the expected values to be defined in the YAML file.

- **description** (optional). This is a description of the YAML file. This does not have a impact on the execution of the tool.
- **extractor** (mandatory). This should be a command string with the name of the extractor tool and all the required parameters needed to connect to the Oracle database. For more detailed information, please refer to the [Data Extractor](#data-extraction) section above.
- **exportDir** (optional). This should be the path of the directory where you want the query files to be saved. If not defined, the default value is: *"./workdir"*
- **dumpDir** (optional). This should be the path of the directory where you want the data dump files to be saved. If not defined, the default value is: *"./dumpdir"*
- **processor** (optional). This should be an integer number representing the amount of parallel processes you want the tool to run with. If not defined, the default value is: *2*
- **schemas** (mandatory). This is a list of Oracle schemas containing a list of schema and query filters. For more detailed information, please refer to the [Query Generation](#query-generation) section.

After creating the YAML file in the root or any other folder, the following command can be used as a reference to run the tool. As of today, all the arguments specified below are mandatory or required by the tool. So, none of them can be omitted and the only part that can be changed is the name of the extraction tool. The real value of all those arguments will be taken from call to the Data Export tool.

`java -jar <path to the final jar file (the jar that includes the lib dependencies)> -host <Oracle host> -port <Oracle port> -sid <Oracle SID> -user <Oracle user> -password <Oracle password> [-configFile <path to the config YAML file>]`

You can use the following command as an example.

`java -jar .\target\oracle-data-export-tool.jar -host localhost -port 1521 -sid orcl -user user1 -password u$3R.ONE -configFile .\exportconfig.yaml`


## Expected Outputs

After the execution of the tool you should expect two folders to be created (one for the exported queries and one for the data dumps) with the names specified in the YAML configuration file. 

### Exported queries folder

Inside the exported queries folder you should see SQL files containing one simple SELECT query for each of the files. Also, you should see a log file named *queryproducer.log*. If there are some columns with not yet supported datatypes, you should see a warning message with the name of that column. 

### Data Dumps

Inside the data dumps folder you should see CSV files, one for each of the SQL files in the exported queries folder. Also, you should see a log file named *queryconsumer.log*. If there were some issues with the execution of the extractor tool and the exit code resulted in something different that 0, then you should see a warning message in the log file.


## YAML Configuration File - Example

Here you can find an example of how the YAML configuration file should look like. 

```yml
# Short description. (optional)
description: "Testing the Oracle Extraction Tool"

# Data extraction tool. (mandatory)
# This should be a command string with the name of the extractor tool and all the required parameters needed to connect to the Oracle database.
# It can be a powershell, batch, or bash script.
extractor: "./extract.sh $host $port $sid $servicename $user $password $filename $outfilename"

# Directory where the queries will be saved. (optional)
# This should be the path of the directory where you want the query files to be saved. If not defined, the default value is: "./workdir"
exportDir: "./exportQueries"

# Directory where the data dumps will be saved. (optional)
# This should be the path of the directory where you want the data dump files to be saved. If not defined, the default value is: "./dumpdir"
dumpDir: "./dataDumps"

# Number of processes running. (optional). 
# This should be an integer number representing the amount of parallel processes you want the tool to run with. If not defined, the default value is: *2*
processes: 4

# Schema and query filter definitions. (mandatory)
schemas: 
  # List of unique schema names
  sh: 
    - schemaFilter: "TABLE_NAME = 'COUNTRIES'"
    - schemaFilter: "TABLE_NAME = 'CUSTOMERS'"
    - schemaFilter: "TABLE_NAME = 'PROMOTIONS'"
    - schemaFilter: "TABLE_NAME = 'PRODUCTS'"
    - schemaFilter: "TABLE_NAME = 'SUPPLEMENTARY_DEMOGRAPHICS'"
    - schemaFilter: "TABLE_NAME = 'TIMES'"
  hr: 
    - schemaFilter: "TABLE_NAME = 'EMPLOYEES'"
    - queryFilter: "EMPLOYEES.HIRE_DATE < '2020-01-01'"
  oe: ~ # A '~' character is used when we want to retrieve all the tables from this schema
  schemaX:
    - schemaFilter: "TABLE_NAME = 'ORDERS'"
      queryFilter: "ORDERS.ORDER_DATE > TO_DATE('2017-10-15', 'YYYY-MM-DD')"
    - schemaFilter: "COLUMN_NAME LIKE 'ORDER_%'"
      queryFilter: ""
  schemaY:
    - schemaFilter: "TABLE_NAME = 'COUNTRIES'"
      queryFilter: "COUNTRIES.CODE IN ('US', 'ES', 'DE')"
```

___

**NOTE:** This tool is under constant improvement. For further information, you can contact <DataEngineeringTeam@mobilize.net>